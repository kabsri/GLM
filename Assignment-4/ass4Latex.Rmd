---
title: "MATH523 Assignment 4"
author: "Kabilan Sriranjan"
date: "March 29, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(aod)
library(VGAM)
library(nnet)
```

## A12

# a)
```{r}
#A12
#A12
game <- 1:24
attempts <- c(4,9,11,6,6,7,7,1,8,9,5,5,5,4,7,3,7,2,11,8,4,4,5,7)
shots <- c(0,7,4,3,5,2,3,0,1,6,0,2,0,2,5,1,3,0,8,0,0,0,2,2)

model.rayallen <- glm(cbind(shots,attempts-shots) ~ 1, family=binomial)
summary(model.rayallen)
pchisq(deviance(model.rayallen), df=23, lower.tail = FALSE)
```
We get a significant p-value from the deviance test, which suggests that the model is not adequate. Perhaps we need to consider the dispersion.

# b)
```{r}
model.rayallen.quasi <- glm(cbind(shots,attempts-shots) ~ 1, family=quasibinomial)
summary(model.rayallen.quasi)
```
The estimate for $\beta$ is the same. This is because we have only scaled the score equations, thus they still have have the same solutions.

# c)
```{r}
rayallen.data <- data.frame(shots, attempts-shots)
model.rayallen.quasi2 <- quasibin(cbind(shots, attempts-shots) ~ 1, data=rayallen.data, link = c("logit"))
model.rayallen.quasi2@fm$coefficients
```
Here the estimate is indeed different from the previous two models. This is because we are changing the likelihood beyond scaling so we changed our solution to the score equations.

# d)
```{r}
model.rayallen.betabin <- vglm(cbind(shots, attempts-shots) ~ 1, betabinomial(zero=2, irho=0.2))
summary(model.rayallen.betabin)
```
We again get different estimates as we are changing the likelihood beyond scaling.

# e)
```{r}
beta.rayallen <- summary(model.rayallen)$coefficients[,1]
stderr.rayallen <- summary(model.rayallen)$coefficients[,2]
beta.quasi <- summary(model.rayallen.quasi)$coefficients[,1]
stderr.quasi <- summary(model.rayallen.quasi)$coefficients[,2]
beta.quasi2 <- model.rayallen.quasi2@fm$coefficients
stderr.quasi2 <- sqrt(vcov(model.rayallen.quasi2))
beta.betabin <- coefficients(summary(model.rayallen.betabin))[,1][1]
stderr.betabin <- coefficients(summary(model.rayallen.betabin))[,2][1]

rayallen.ci <- c(beta.rayallen - qnorm(0.975)*stderr.rayallen, beta.rayallen + qnorm(0.975)*stderr.rayallen)
quasi.ci <- c(beta.quasi - qnorm(0.975)*stderr.quasi, beta.quasi + qnorm(0.975)*stderr.quasi)
quasi2.ci <- c(beta.quasi2 - qnorm(0.975)*stderr.quasi2, beta.quasi2 + qnorm(0.975)*stderr.quasi2)
betabin.ci <- c(beta.betabin - qnorm(0.975)*stderr.betabin, beta.betabin + qnorm(0.975)*stderr.betabin)

rayallen.ci
quasi.ci
quasi2.ci
betabin.ci
```
Here we have all the confidence intervals for $\beta$ in every model. $\beta$ represents the log odds of Ray Allen making a shot, taking into account that he usually either has a very good succcess rate or very bad one.

# f)
A variable that could affect his success rate in a game would be the opposing team. It may be harder to get a 3-point shot against some teams, and maybe certain teams cause him to be more nervous and perform worse. The betabinomial model has an extra parameter so it can account for the fact that there is some randomness to whether he has a high success rate or a low one.

## A13

# a)

```{r}
#A13
I <- c(14, 483, 497, 1008)
notI <- c(1105, 411111, 4624, 157342)
S <- c("Seat belt", "Seat belt", "None", "None")
E <- c("Yes", "No", "Yes", "No")

model.fatal <- glm(cbind(I, notI) ~ S+E, family=binomial)
#likelihood test
pchisq(deviance(model.fatal), df=1, lower.tail=FALSE)
#pearson chi square test
pchisq(sum(residuals(model.fatal, type="pearson")^2), df=1, lower.tail=FALSE)
```

The p-values we get using both tests are not significant, which means that our model is adequate.

# b)

```{r}
summary(model.fatal)
beta <- coef(model.fatal)
odds.ratio <- exp(beta)
stdErr <- summary(model.fatal)$coefficients[,2]

lowerCI <- exp(beta-qnorm(0.975)*stdErr)
higherCI <- exp(beta+qnorm(0.975)*stdErr)
#Odds ratio and confidence interval for Seatbelt
odds.ratio[2]
lowerCI[2]
higherCI[2]
#Odds ratio and confidence interval for Ejected
odds.ratio[3]
lowerCI[3]
higherCI[3]
```

The odds ratio, $r$, for Seatbelt can be obtained by
\begin{align*}
r &= \frac{e^{\beta_0 + \beta_1(1) + \beta_2x_{i2}}}{e^{\beta_0 + \beta_1(0) + \beta_2x_{i2}}} \\
&= e^{\beta_1}
\end{align*}
And we can do the same for $\beta_2$ to get the odds ratio for Ejected.
The confidence intervals are obtained through the formula $\widehat{\beta}\pm se(\widehat{\beta})z_{0.025}$ 

# c)

```{r}
model.fatal2 <- glm(cbind(I, notI) ~ E, family=binomial)
beta2 <- coef(model.fatal2)
odds.ratio2 <- exp(beta2)
stdErr2 <- summary(model.fatal2)$coefficients[,2]
lowerCI2 <- exp(beta2-qnorm(0.975)*stdErr2)
higherCI2 <- exp(beta2+qnorm(0.975)*stdErr2)

#Odds and confidence interval
odds.ratio2[2]
lowerCI2[2]
higherCI2[2]
```

We compute the odds ratio and confidence interval for the new model the exact same way as before.

## A14

# a) 

```{r}
#A14
race <- c(1, 1, 0, 0)
gender <- c(1, 0, 1, 0)
heaven.yes <- c(88, 54, 397, 235)
heaven.mb <- c(16, 7, 141, 189)
heaven.no <- c(2, 5, 24, 39)

model.heaven <- multinom(cbind(heaven.yes, heaven.mb, heaven.no) ~ race+gender)
summary(model.heaven)
```

$log(\pi_{i1}/\pi_{i3})$ is given by 
\[
\alpha_1 + \beta_{1}^Gx_{i1} + \beta_{1}^Rx_{i2}
\]

$log(\pi_{i2}/\pi_{i3})$ is given by
\[
\alpha_2 + \beta_{2}^Gx_{i1} + \beta_{2}^Rx_{i2}
\]

$log(\pi_{i1}/\pi_{i2})$ is given by
\[
log(\pi_{i1}/\pi_{i3}) - log(\pi_{i2}/\pi_{i3})
\]

# b)
```{r}
model.heavenB <- glm(cbind(heaven.yes, heaven.no) ~ race+gender, family=binomial)
summary(model.heavenB)

beta.gender <- coef(model.heavenB)[3]
stderr.gender <- summary(model.heavenB)$coefficients[,2][3]
gender.oddsratio <- exp(beta.gender)
lowerCI.gender <- exp(beta.gender-qnorm(0.975)*stderr.gender)
higherCI.gender <- exp(beta.gender+qnorm(0.975)*stderr.gender)
#Odds ratio and confidence interval
gender.oddsratio
lowerCI.gender
higherCI.gender
```

From looking at the odds ratio it appears that males have roughly triple the odds of not believing in heaven than females.

# c)
```{r}
model.heavenRace <- glm(cbind(heaven.yes, heaven.no) ~ race, family=binomial)
summary(model.heavenRace)
anova(model.heavenB, model.heavenRace, test="Chi")
```

We can check if gender has an effect on the response when race is controlled by comparing the model with both race and gender to the model with only race. If the test is significant that that means the nested model is not an adequte simplification and so gender does indeed affect the response. Since we do get a significant p-value then that means belief in heaven is not independant of gender when race is controlled for.


## A15

If the binary response is the result of an underlying latent variable, this suggests that after some certain threshold, $T$, the response changes from O to 1. If both groups have similar location then they are both close to $T$. But because one has significantly higher dispersion than the other, it will have a wide confidence interval that overlaps with the other side of $T$. This makes it hard to fit a model because if a response is 0 we can't tell if it is truly 0 or actually 1 but the dispersion makes it fall on the wrong side of $T$.